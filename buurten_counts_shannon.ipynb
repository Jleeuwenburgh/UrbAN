{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import classes.entropycalculator as ec\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "import gc\n",
    "import shapely\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "bu = gpd.read_parquet('data/buurten_concatenated.parquet')\n",
    "\n",
    "categorisation = pd.read_excel('data/categorisation.xlsx')\n",
    "L0_cats = categorisation['L0 category'].unique()\n",
    "L1_cats = categorisation['L1 category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_shannon_entropy(labels, base=2):\n",
    "    # get the total count of the labels\n",
    "    total_count = len(labels)\n",
    "    # get the unique labels and their counts\n",
    "    _, label_counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "    probs = label_counts / total_count\n",
    "    # get the entropy\n",
    "    return entropy(probs, base=base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(bu.iterrows(), total=bu.shape[0]):\n",
    "    amenities = gpd.read_parquet(f\"data/gm_amenities/amenities_{row['gemeentenaam']}.parquet\")\n",
    "    amenities = amenities[amenities.geometry.within(row.geometry)]\n",
    "    for filter_i in [0, 1, 2]:\n",
    "        \n",
    "        # get and apply filter\n",
    "        L0_filter, L1_filter = ec.getfilter(filter_i)\n",
    "        \n",
    "        amenities_f = amenities[~amenities.L0_category.isin(L0_filter)]\n",
    "        if L1_filter:\n",
    "            for key, value in L1_filter.items():\n",
    "                amenities_f = amenities_f[\n",
    "                    ~( (amenities_f.L0_category == key) & (amenities_f.L1_category.isin(value)) )\n",
    "                ]\n",
    "        \n",
    "        bu.at[idx, f'L0_shannon_{filter_i}'] = _get_shannon_entropy(amenities_f.L0_category.values)\n",
    "        bu.at[idx, f'L1_shannon_{filter_i}'] = _get_shannon_entropy(amenities_f.L1_category.values)\n",
    "        \n",
    "        for cat in L0_cats:\n",
    "            bu.loc[idx, f'L1_{filter_i}_count_{cat}'] = len(amenities_f[amenities_f.L0_category == cat])\n",
    "        \n",
    "        for cat in L1_cats:\n",
    "            bu.loc[idx, f'L0_{filter_i}_count_{cat}'] = len(amenities_f[amenities_f.L1_category == cat])\n",
    "\n",
    "    del amenities\n",
    "    del amenities_f\n",
    "    gc.collect()\n",
    "\n",
    "bu.to_parquet('data/buurten_concatenated_sh.parquet') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scriptie_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
